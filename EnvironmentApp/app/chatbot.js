import React, { useState, useRef, useEffect } from 'react';
import { View, FlatList, TextInput, KeyboardAvoidingView, Platform, Keyboard, Alert, TouchableOpacity } from 'react-native';
import { Text, ActivityIndicator, IconButton, Avatar, Chip } from 'react-native-paper';
import { useRouter, Stack } from 'expo-router';
import * as Speech from 'expo-speech';
import { Audio } from 'expo-av';
import * as FileSystem from 'expo-file-system';
import { auth, db } from '../firebaseConfig';
import { addDoc, collection, query, orderBy, limit, getDocs } from 'firebase/firestore';

import { styles } from '../styles/chatbot.styles';

// Láº¥y key tá»« biáº¿n mÃ´i trÆ°á»ng.
const GEMINI_API_KEY = process.env.EXPO_PUBLIC_GEMINI_API_KEY; 

export default function ChatbotScreen() {
Â  const router = useRouter();
Â  const [messages, setMessages] = useState([
Â  Â  { id: '1', text: 'ChÃ o báº¡n! TÃ´i lÃ  trá»£ lÃ½ mÃ´i trÆ°á»ng AI. Báº¡n cáº§n giÃºp gÃ¬ khÃ´ng?', sender: 'bot', timestamp: Date.now() }
Â  ]);
Â  const [inputText, setInputText] = useState('');
Â  const [loading, setLoading] = useState(false);
Â  const [isSpeaking, setIsSpeaking] = useState(false);
Â  const [recording, setRecording] = useState(null);
Â  const flatListRef = useRef(null);

Â  useEffect(() => {
Â  Â  const loadHistory = async () => {
Â  Â  Â  const user = auth.currentUser;
Â  Â  Â  if (!user) return;
Â  Â  Â  try {
Â  Â  Â  Â  const q = query(collection(db, `users/${user.uid}/chatHistory`), orderBy('timestamp', 'desc'), limit(15));
Â  Â  Â  Â  const snapshot = await getDocs(q);
Â  Â  Â  Â  const history = snapshot.docs.map(doc => ({ id: doc.id, ...doc.data() })).reverse();
Â  Â  Â  Â  if (history.length > 0) setMessages(prev => [...prev, ...history.slice(1)]);
Â  Â  Â  } catch (error) {
Â  Â  Â  Â  console.log("Lá»—i táº£i lá»‹ch sá»­ chat:", error);
Â  Â  Â  }
Â  Â  };
Â  Â  loadHistory();

Â  Â  return () => {
Â  Â  Â  Speech.stop();
Â  Â  Â  if (recording) recording.stopAndUnloadAsync();
Â  Â  };
Â  }, []);

Â  const startRecording = async () => {
Â  Â  try {
Â  Â  Â  const perm = await Audio.requestPermissionsAsync();
Â  Â  Â  if (perm.status !== 'granted') {
Â  Â  Â  Â  Alert.alert("Lá»—i", "Cáº§n quyá»n truy cáº­p Microphone.");
Â  Â  Â  Â  return;
Â  Â  Â  }

Â  Â  Â  await Audio.setAudioModeAsync({ allowsRecordingIOS: true, playsInSilentModeIOS: true });

Â  Â  Â  const recordingOptions = {
Â  Â  Â  Â  android: {
Â  Â  Â  Â  Â  extension: '.m4a',
Â  Â  Â  Â  Â  outputFormat: Audio.AndroidOutputFormat.MPEG_4,
Â  Â  Â  Â  Â  audioEncoder: Audio.AndroidAudioEncoder.AAC,
Â  Â  Â  Â  Â  sampleRate: 44100,
Â  Â  Â  Â  Â  numberOfChannels: 2,
Â  Â  Â  Â  Â  bitRate: 128000,
Â  Â  Â  Â  },
Â  Â  Â  Â  ios: {
Â  Â  Â  Â  Â  extension: '.m4a',
Â  Â  Â  Â  Â  audioQuality: Audio.IOSAudioQuality.HIGH,
Â  Â  Â  Â  Â  sampleRate: 44100,
Â  Â  Â  Â  Â  numberOfChannels: 2,
Â  Â  Â  Â  Â  bitRate: 128000,
Â  Â  Â  Â  Â  linearPCMBitDepth: 16,
Â  Â  Â  Â  Â  linearPCMIsBigEndian: false,
Â  Â  Â  Â  Â  linearPCMIsFloat: false,
Â  Â  Â  Â  },
Â  Â  Â  Â  web: {
Â  Â  Â  Â  Â  mimeType: 'audio/webm',
Â  Â  Â  Â  Â  bitsPerSecond: 128000,
Â  Â  Â  Â  },
Â  Â  Â  };

Â  Â  Â  const { recording } = await Audio.Recording.createAsync(recordingOptions);
Â  Â  Â  setRecording(recording);
Â  Â  } catch (err) {
Â  Â  Â  console.error("Lá»—i ghi Ã¢m:", err);
Â  Â  Â  Alert.alert('Lá»—i', 'KhÃ´ng thá»ƒ ghi Ã¢m.');
Â  Â  }
Â  };

Â  const stopRecording = async () => {
Â  Â  if (!recording) return;
Â  Â  try {
Â  Â  Â  await recording.stopAndUnloadAsync();
Â  Â  Â  const uri = recording.getURI();
Â  Â  Â  setRecording(null);
Â  Â  Â  if (uri) handleSendAudio(uri);
Â  Â  } catch (err) {
Â  Â  Â  console.error("Lá»—i dá»«ng ghi Ã¢m:", err);
Â  Â  }
Â  };

Â  const handleSendAudio = async (uri) => {
Â  Â  const user = auth.currentUser;
Â  Â  const userMsg = { id: Date.now().toString(), text: "ğŸ¤ (Äang gá»­i giá»ng nÃ³i...)", sender: 'user', timestamp: Date.now(), isAudio: true };
Â  Â  setMessages(prev => [...prev, userMsg]);
Â  Â  setLoading(true);

Â  Â  try {
Â  Â  Â  Â  const base64Audio = await FileSystem.readAsStringAsync(uri, { encoding: 'base64' });

Â  Â  Â  Â  const response = await fetch(
Â  Â  Â  Â  Â  Â  // ÄÃƒ Sá»¬A: DÃ¹ng API Key qua query parameter
Â  Â  Â  Â  Â  Â  `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${GEMINI_API_KEY}`,
Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  method: 'POST',
Â  Â  Â  Â  Â  Â  Â  Â  headers: { 'Content-Type': 'application/json' }, 
Â  Â  Â  Â  Â  Â  Â  Â  body: JSON.stringify({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  contents: [{
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  parts: [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  { text: "HÃ£y nghe Ä‘oáº¡n Ã¢m thanh nÃ y vÃ  tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng má»™t cÃ¡ch ngáº¯n gá»n, thÃ¢n thiá»‡n báº±ng tiáº¿ng Viá»‡t." },
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  { inline_data: { mime_type: "audio/m4a", data: base64Audio } }
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }]
Â  Â  Â  Â  Â  Â  Â  Â  })
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  );

Â  Â  Â  Â  const data = await response.json();
Â  Â  Â  Â  
Â  Â  Â  Â  if (data.error) throw new Error(data.error.message || "Lá»—i tá»« Gemini API");
Â  Â  Â  Â  
Â  Â  Â  Â  const botText = data.candidates?.[0]?.content?.parts?.[0]?.text || "TÃ´i khÃ´ng nghe rÃµ, báº¡n nÃ³i láº¡i Ä‘Æ°á»£c khÃ´ng?";
Â  Â  Â  Â  
Â  Â  Â  Â  const botMsg = { id: (Date.now() + 1).toString(), text: botText, sender: 'bot', timestamp: Date.now() };
Â  Â  Â  Â  setMessages(prev => [...prev, botMsg]);

Â  Â  Â  Â  if (user) addDoc(collection(db, `users/${user.uid}/chatHistory`), botMsg);
Â  Â  Â  Â  speakText(botText);

Â  Â  } catch (error) {
Â  Â  Â  Â  console.error("Lá»—i xá»­ lÃ½ audio:", error);
Â  Â  Â  Â  Alert.alert("Lá»—i AI", error.message || "KhÃ´ng thá»ƒ xá»­ lÃ½ Ã¢m thanh.");
Â  Â  } finally {
Â  Â  Â  Â  setLoading(false);
Â  Â  }
Â  };

Â  const sendMessage = async (customText) => {
Â  Â  const textToSend = customText || inputText;
Â  Â  if (!textToSend.trim()) return;

Â  Â  const user = auth.currentUser;
Â  Â  const userMsg = { id: Date.now().toString(), text: textToSend, sender: 'user', timestamp: Date.now() };

Â  Â  setMessages(prev => [...prev, userMsg]);
Â  Â  setInputText('');
Â  Â  Keyboard.dismiss();
Â  Â  Speech.stop();
Â  Â  setIsSpeaking(false);

Â  Â  if (user) addDoc(collection(db, `users/${user.uid}/chatHistory`), userMsg);

Â  Â  setLoading(true);
Â  Â  try {
Â  Â  Â  Â  const response = await fetch(
Â  Â  Â  Â  Â  Â  // ÄÃƒ Sá»¬A: DÃ¹ng API Key qua query parameter
Â  Â  Â  Â  Â  Â  `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${GEMINI_API_KEY}`,
Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  method: 'POST',
Â  Â  Â  Â  Â  Â  Â  Â  headers: { 'Content-Type': 'application/json' }, 
Â  Â  Â  Â  Â  Â  Â  Â  body: JSON.stringify({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  contents: [{ parts: [{ text: `Báº¡n lÃ  chuyÃªn gia mÃ´i trÆ°á»ng. HÃ£y tráº£ lá»i ngáº¯n gá»n: ${textToSend}` }] }]
Â  Â  Â  Â  Â  Â  Â  Â  })
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  );

Â  Â  Â  Â  const data = await response.json();
Â  Â  Â  Â  if (data.error) throw new Error(data.error.message);

Â  Â  Â  Â  const botText = data.candidates?.[0]?.content?.parts?.[0]?.text || "Lá»—i káº¿t ná»‘i AI.";
Â  Â  Â  Â  const botMsg = { id: (Date.now() + 1).toString(), text: botText, sender: 'bot', timestamp: Date.now() };
Â  Â  Â  Â  setMessages(prev => [...prev, botMsg]);
Â  Â  Â  Â  if (user) addDoc(collection(db, `users/${user.uid}/chatHistory`), botMsg);
Â  Â  Â  Â  speakText(botText);

Â  Â  } catch (error) {
Â  Â  Â  Â  console.error("Lá»—i chat text:", error);
Â  Â  Â  Â  Alert.alert("Lá»—i", "AI khÃ´ng pháº£n há»“i.");
Â  Â  } finally {
Â  Â  Â  Â  setLoading(false);
Â  Â  }
Â  };

Â  const speakText = (text) => {
Â  Â  setIsSpeaking(true);
Â  Â  Speech.speak(text, {
Â  Â  Â  language: 'vi-VN',
Â  Â  Â  rate: 0.9,
Â  Â  Â  onDone: () => setIsSpeaking(false),
Â  Â  Â  onStopped: () => setIsSpeaking(false),
Â  Â  Â  onError: () => setIsSpeaking(false)
Â  Â  });
Â  };

Â  const stopSpeaking = () => { Speech.stop(); setIsSpeaking(false); };

Â  const renderMessage = ({ item }) => {
Â  Â  const isUser = item.sender === 'user';
Â  Â  return (
Â  Â  Â  <View style={[styles.msgContainer, isUser ? styles.msgRight : styles.msgLeft]}>
Â  Â  Â  Â  {!isUser && <Avatar.Icon size={32} icon="leaf" style={styles.botAvatar} color="#0E4626" />}
Â  Â  Â  Â  <View style={isUser ? styles.bubbleRight : styles.bubbleLeft}>
Â  Â  Â  Â  Â  <Text style={isUser ? styles.textRight : styles.textLeft}>{item.text}</Text>
Â  Â  Â  Â  </View>
Â  Â  Â  </View>
Â  Â  );
Â  };

Â  return (
Â  Â  <View style={styles.container}>
Â  Â  Â  <Stack.Screen options={{ headerShown: false }} />

Â  Â  Â  <View style={styles.headerBar}>
Â  Â  Â  Â  <IconButton icon="arrow-left" onPress={() => router.back()} iconColor="#0E4626" size={26} style={styles.backBtn} />
Â  Â  Â  Â  <Text style={styles.headerTitle}>Trá»£ lÃ½ AI</Text>
Â  Â  Â  Â  {isSpeaking && <IconButton icon="volume-off" onPress={stopSpeaking} iconColor="#D32F2F" size={24} />}
Â  Â  Â  </View>

Â  Â  Â  <FlatList
Â  Â  Â  Â  ref={flatListRef}
Â  Â  Â  Â  data={messages}
Â  Â  Â  Â  keyExtractor={(item) => item.id}
Â  Â  Â  Â  renderItem={renderMessage}
Â  Â  Â  Â  contentContainerStyle={styles.chatContent}
Â  Â  Â  Â  style={{ flex: 1 }}
Â  Â  Â  Â  onContentSizeChange={() => flatListRef.current?.scrollToEnd({ animated: true })}
Â  Â  Â  Â  ListFooterComponent={loading ? <ActivityIndicator size="small" color="#0E4626" style={{ marginTop: 10 }} /> : null}
Â  Â  Â  />

Â  Â  Â  <View style={{ maxHeight: 50 }}>
Â  Â  Â  Â  <FlatList
Â  Â  Â  Â  Â  horizontal
Â  Â  Â  Â  Â  showsHorizontalScrollIndicator={false}
Â  Â  Â  Â  Â  data={["CÃ¡ch tÃ¡i cháº¿ pin?", "PhÃ¢n loáº¡i rÃ¡c nhá»±a?", "Máº¹o tiáº¿t kiá»‡m Ä‘iá»‡n"]}
Â  Â  Â  Â  Â  contentContainerStyle={styles.chipContainer}
Â  Â  Â  Â  Â  renderItem={({ item }) => (
Â  Â  Â  Â  Â  Â  <Chip onPress={() => sendMessage(item)} style={styles.chipItem} textStyle={styles.chipText} icon="sprout">
Â  Â  Â  Â  Â  Â  Â  {item}
Â  Â  Â  Â  Â  Â  </Chip>
Â  Â  Â  Â  Â  )}
Â  Â  Â  Â  />
Â  Â  Â  </View>

Â  Â  Â  <KeyboardAvoidingView behavior={Platform.OS === 'ios' ? 'padding' : undefined}>
Â  Â  Â  Â  {recording && <Text style={styles.recordingText}>Äang nghe... (Tháº£ tay Ä‘á»ƒ gá»­i)</Text>}

Â  Â  Â  Â  <View style={styles.inputWrapper}>
Â  Â  Â  Â  Â  <TouchableOpacity
Â  Â  Â  Â  Â  Â  onPressIn={startRecording}
Â  Â  Â  Â  Â  Â  onPressOut={stopRecording}
Â  Â  Â  Â  Â  Â  style={[styles.micBtn, recording ? styles.micBtnActive : null]}
Â  Â  Â  Â  Â  >
Â  Â  Â  Â  Â  Â  <IconButton icon="microphone" iconColor={recording ? '#D32F2F' : '#0E4626'} size={24} style={{ margin: 0 }} />
Â  Â  Â  Â  Â  </TouchableOpacity>

Â  Â  Â  Â  Â  <TextInput
Â  Â  Â  Â  Â  Â  style={[styles.textInput, { maxHeight: 100 }]}
Â  Â  Â  Â  Â  Â  placeholder="Nháº­p cÃ¢u há»i..."
Â  Â  Â  Â  Â  Â  value={inputText}
Â  Â  Â  Â  Â  Â  onChangeText={setInputText}
Â  Â  Â  Â  Â  Â  onSubmitEditing={() => sendMessage()}
Â  Â  Â  Â  Â  Â  editable={!recording}
Â  Â  Â  Â  Â  Â  placeholderTextColor="#999"
Â  Â  Â  Â  Â  Â  multiline
Â  Â  Â  Â  Â  />

Â  Â  Â  Â  Â  <TouchableOpacity
Â  Â  Â  Â  Â  Â  style={[styles.sendBtn, { opacity: (!inputText.trim() && !loading) ? 0.5 : 1 }]}
Â  Â  Â  Â  Â  Â  onPress={() => sendMessage()}
Â  Â  Â  Â  Â  Â  disabled={loading || !inputText.trim()}
Â  Â  Â  Â  Â  >
Â  Â  Â  Â  Â  Â  <IconButton icon="send" iconColor="#fff" size={20} style={{ margin: 0 }} />
Â  Â  Â  Â  Â  </TouchableOpacity>
Â  Â  Â  Â  </View>
Â  Â  Â  </KeyboardAvoidingView>
Â  Â  </View>
Â  );
}